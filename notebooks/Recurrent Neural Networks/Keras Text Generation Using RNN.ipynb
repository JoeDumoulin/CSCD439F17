{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a text generation example using RNN units with LSTM.  the example is from [this github page](https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600893\n",
      "total chars: 57\n",
      "nb sequences: 200285\n",
      "Vectorization...\n",
      "Build model...\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Epoch 1/15\n",
      "200285/200285 [==============================] - 86s 430us/step - loss: 2.0033\n",
      "Epoch 2/15\n",
      "200285/200285 [==============================] - 85s 425us/step - loss: 1.6485\n",
      "Epoch 3/15\n",
      "200285/200285 [==============================] - 85s 424us/step - loss: 1.5550\n",
      "Epoch 4/15\n",
      "200285/200285 [==============================] - 85s 422us/step - loss: 1.5082\n",
      "Epoch 5/15\n",
      "200285/200285 [==============================] - 85s 422us/step - loss: 1.4779\n",
      "Epoch 6/15\n",
      "200285/200285 [==============================] - 85s 424us/step - loss: 1.4549\n",
      "Epoch 7/15\n",
      "200285/200285 [==============================] - 85s 425us/step - loss: 1.4398\n",
      "Epoch 8/15\n",
      "200285/200285 [==============================] - 85s 424us/step - loss: 1.4231\n",
      "Epoch 9/15\n",
      "200285/200285 [==============================] - 85s 425us/step - loss: 1.4127\n",
      "Epoch 10/15\n",
      "200285/200285 [==============================] - 85s 425us/step - loss: 1.4028\n",
      "Epoch 11/15\n",
      "200285/200285 [==============================] - 85s 424us/step - loss: 1.3941\n",
      "Epoch 12/15\n",
      "200285/200285 [==============================] - 85s 425us/step - loss: 1.3884\n",
      "Epoch 13/15\n",
      "200285/200285 [==============================] - 85s 424us/step - loss: 1.3802\n",
      "Epoch 14/15\n",
      "200285/200285 [==============================] - 85s 427us/step - loss: 1.3751\n",
      "Epoch 15/15\n",
      "200285/200285 [==============================] - 85s 426us/step - loss: 1.3711\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"espiser.\n",
      "\n",
      "79. a soul which knows that it\"\n",
      "espiser.\n",
      "\n",
      "79. a soul which knows that it is the preaches of the profound and self-desirative and most strength and sense of the sense of the sense of the strength and soul the strength of the self-deceived to the south in the contrary of the true and the strength and science of the sense of the present and all the present and all the strength and a strength of the strength of the south in the present and a strength and all the present a\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"espiser.\n",
      "\n",
      "79. a soul which knows that it\"\n",
      "espiser.\n",
      "\n",
      "79. a soul which knows that it is all the himselity and the the artists and souls an our fepely has also a germine and the most angey, the lives himself and the entire strength and imperative think of the subject has all the same further and soul the sense in the prided to the retaid to some strength and specially men of man in the end a will a soul and inable out of easiers of the subject, he origination of the encourable sid\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"espiser.\n",
      "\n",
      "79. a soul which knows that it\"\n",
      "espiser.\n",
      "\n",
      "79. a soul which knows that it because of a have\n",
      "the masted canity is made far old\n",
      "things when thelm---or purpisem the anbased up he\n",
      "prevent, that provement. this indivispol\n",
      "standard and very revelopment,\n",
      "procealisty and\n",
      "most enasment and daccene fune of moral word which carety, and\n",
      "drame the pains is extran men. the philosophical prefered the are estimate\n",
      "comple, their conscience ageely,\n",
      "\"honestys,oution of geners! and eduage\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"espiser.\n",
      "\n",
      "79. a soul which knows that it\"\n",
      "espiser.\n",
      "\n",
      "79. a soul which knows that it) adnan philosophy yet contempt \"and unreancknessly sympaomy? allen himadyt life honle, their neceacy. the\n",
      "faverwincs would too, mor the eavini-exphelarnian midcobaguand. bounder, but light\" the\n",
      "distuations inreceptics, also insingund badwer, probably uramiles mty condation only venge refrued, chapted\n",
      "to his withinguriatca, inagmoristhess, enbound! the belief further-man, intendity and\n",
      "swag, to be\n"
     ]
    }
   ],
   "source": [
    "'''Example script to generate text from Nietzsche's writings.\n",
    "At least 20 epochs are required before the generated text\n",
    "starts sounding coherent.\n",
    "It is recommended to run this script on GPU, as recurrent\n",
    "networks are quite computationally intensive.\n",
    "If you try this script on new data, make sure your corpus\n",
    "has at least ~100k characters. ~1M is better.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "\n",
    "path = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "text = open(path).read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "\n",
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "# train the model, output generated text after each iteration\n",
    "for iteration in range(1, 2):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model.fit(x, y,\n",
    "              batch_size=128,\n",
    "              epochs=15)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print()\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
